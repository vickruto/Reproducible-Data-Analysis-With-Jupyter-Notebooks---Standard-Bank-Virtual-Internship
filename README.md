### Reproducible Data Analysis with Jupyter Notebooks

#### Standard Bank Virtual Internship

Jupyter notebooks are very useful for interactive and experimental exploration of data.

The aim of this repo is to practically explore how Jupyter IPython notebooks can be integrated into a workflow that ensures reproducible data analysis based on organized, packaged and tested code. For this case study, I will be using the Standard Bank Virtual Internship Task 2 from  the [Forage](theforage.com) virtual work experiences. 

The objective of the task is to implement a model that will assess the credit worthiness of a loan applicant to predict whether the potential borrower will default on his/her loan or not. The dataset used is available on [Kaggle](https://www.kaggle.com/datasets/altruistdelhite04/loan-prediction-problem-dataset). To achieve the objective, the data has to be assessed, cleaned and prepared for modelling. The data then has to be modelled and the model built evaluated. Part of the objective of the task is to determine whether a bespoke Scikit-learn model has to be built or whether an autoML solution will be good enough. 

A lot is borrowed from this [Youtube tutorial series](https://www.youtube.com/playlist?list=PLYCpMb24GpOC704uO9svUrihl-HY1tTJJ) by Jake Vanderplas

